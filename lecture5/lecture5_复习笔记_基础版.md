# Lecture 5 è¶…åŸºç¡€å¤ä¹ ç¬”è®° - æ­£åˆ™è¡¨è¾¾å¼è¿›é˜¶ & æ–‡æœ¬é¢„å¤„ç†

## é›¶ã€å…ˆç†è§£é—®é¢˜

### Lecture 5åˆ†ä¸ºä¸¤éƒ¨åˆ†

**Part Aï¼šæ­£åˆ™è¡¨è¾¾å¼è¿›é˜¶**
- å¤„ç†HTMLæ ‡ç­¾
- æå–URLé“¾æ¥
- ä½¿ç”¨åå‘å¼•ç”¨ï¼ˆbackreferencesï¼‰

**Part Bï¼šæ–‡æœ¬é¢„å¤„ç†**
- åˆ†è¯ï¼ˆTokenizationï¼‰
- å°å†™è½¬æ¢ï¼ˆLowercasingï¼‰
- Twitterç‰¹æ®Šå…ƒç´ å¤„ç†ï¼ˆ@mentions, #hashtags, emojisï¼‰
- ç±»å‹-æ ‡è®°æ¯”ç‡ï¼ˆType-Token Ratio, TTRï¼‰

---

## Part Aï¼šæ­£åˆ™è¡¨è¾¾å¼è¿›é˜¶ï¼ˆHTMLè§£æï¼‰

### ä¸€ã€é—®é¢˜èƒŒæ™¯

**ä»»åŠ¡ï¼š**ä»HTMLæ–‡ä»¶ä¸­æå–ä¿¡æ¯

```html
<html>
<head>
<title>COM6115: Text Processing</title>
</head>
<body>
<p>This is a <b>bold</b> word.</p>
<a href="http://example.com">Link</a>
</body>
</html>
```

**éœ€è¦æå–ï¼š**
1. HTMLæ ‡ç­¾ï¼ˆå¦‚ `<p>`, `<b>`, `</p>`ï¼‰
2. åŒºåˆ†å¼€æ ‡ç­¾å’Œé—­æ ‡ç­¾
3. æ ‡ç­¾å‚æ•°ï¼ˆå¦‚ `href="..."`ï¼‰
4. URLé“¾æ¥
5. é…å¯¹çš„æ ‡ç­¾ä¹‹é—´çš„æ–‡æœ¬

---

### äºŒã€æ ¸å¿ƒæ¦‚å¿µ

#### 1. è´ªå©ªåŒ¹é… vs éè´ªå©ªåŒ¹é…

**è´ªå©ªåŒ¹é…ï¼ˆGreedyï¼‰ï¼š**å°½å¯èƒ½å¤šåœ°åŒ¹é…

```python
text = "<p><b>text</b></p>"

# è´ªå©ªåŒ¹é…
pattern = '<.*>'
# åŒ¹é…ç»“æœï¼š<p><b>text</b></p>  â† æ•´ä¸ªå­—ç¬¦ä¸²ï¼
```

**ä¸ºä»€ä¹ˆï¼Ÿ**
```
'.*' è¡¨ç¤ºï¼šåŒ¹é…ä»»æ„å­—ç¬¦ï¼Œä»»æ„å¤šæ¬¡
ä»ç¬¬ä¸€ä¸ª '<' å¼€å§‹ï¼Œä¸€ç›´åˆ°æœ€åä¸€ä¸ª '>'
```

**é—®é¢˜ï¼š**æˆ‘ä»¬æƒ³è¦åˆ†åˆ«åŒ¹é…æ¯ä¸ªæ ‡ç­¾ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡å…¨åŒ¹é…ï¼

---

**éè´ªå©ªåŒ¹é…ï¼ˆNon-greedyï¼‰ï¼š**å°½å¯èƒ½å°‘åœ°åŒ¹é…

```python
text = "<p><b>text</b></p>"

# éè´ªå©ªåŒ¹é…
pattern = '<.*?>'
# åŒ¹é…ç»“æœï¼š<p>, <b>, </b>, </p>  â† 4ä¸ªå•ç‹¬çš„æ ‡ç­¾ï¼
```

**`?` çš„ä½œç”¨ï¼š**
```
'.*?' è¡¨ç¤ºï¼šåŒ¹é…ä»»æ„å­—ç¬¦ï¼Œä½†å°½å¯èƒ½å°‘
é‡åˆ°ç¬¬ä¸€ä¸ª '>' å°±åœæ­¢
```

---

#### 2. å­—ç¬¦ç±»å–å `[^...]`

**å«ä¹‰ï¼š**åŒ¹é…**ä¸åœ¨**æ‹¬å·å†…çš„ä»»æ„å­—ç¬¦

```python
# ä¾‹å­1ï¼šåŒ¹é…éæ•°å­—
pattern = '[^0-9]'
text = "a1b2c3"
# åŒ¹é…ï¼ša, b, cï¼ˆä¸åŒ¹é…æ•°å­—ï¼‰

# ä¾‹å­2ï¼šåŒ¹é…HTMLæ ‡ç­¾ï¼ˆä¸åŒ…å«>ï¼‰
pattern = '<[^>]+>'
text = "<p><b>text</b></p>"
# åŒ¹é…ï¼š<p>, <b>, </b>, </p>
```

**ä¸ºä»€ä¹ˆæœ‰æ•ˆï¼Ÿ**
```
'<[^>]+>' çš„æ„æ€ï¼š
< â† ä»¥ < å¼€å§‹
[^>]+ â† åŒ¹é…1ä¸ªæˆ–å¤šä¸ª"ä¸æ˜¯>"çš„å­—ç¬¦
> â† ä»¥ > ç»“æŸ

è¿™æ ·å°±ä¸ä¼šè·¨è¶Šå¤šä¸ªæ ‡ç­¾ï¼
```

---

#### 3. åå‘å¼•ç”¨ï¼ˆBackreferencesï¼‰

**é—®é¢˜ï¼š**å¦‚ä½•åŒ¹é…é…å¯¹çš„æ ‡ç­¾ï¼Ÿ

```html
<b>bold text</b>  â† æ­£ç¡®é…å¯¹
<b>bold text</i>  â† é”™è¯¯é…å¯¹ï¼
```

**åå‘å¼•ç”¨è¯­æ³•ï¼š**`\1`, `\2`, `\3`...

```python
# åŒ¹é…é…å¯¹çš„å¼€é—­æ ‡ç­¾
pattern = r'<(\w+)>(.*?)</\1>'
```

**è¯¦ç»†è§£é‡Šï¼š**

```
r'<(\w+)>(.*?)</\1>'
   â†‘      â†‘     â†‘
   |      |     â””â”€ åå‘å¼•ç”¨ç¬¬1ç»„ï¼ˆå¿…é¡»åŒ¹é…ç›¸åŒçš„æ ‡ç­¾åï¼‰
   |      â””â”€ ç¬¬2ç»„ï¼šæ ‡ç­¾ä¹‹é—´çš„æ–‡æœ¬ï¼ˆéè´ªå©ªï¼‰
   â””â”€ ç¬¬1ç»„ï¼šæ ‡ç­¾åï¼ˆç”¨æ‹¬å·æ•è·ï¼‰

ä¾‹å­ï¼š
<b>text</b>
ç¬¬1ç»„åŒ¹é…ï¼šb
ç¬¬2ç»„åŒ¹é…ï¼štext
\1 è¦æ±‚ï¼šä¹Ÿå¿…é¡»æ˜¯ bï¼ˆæ‰€ä»¥ </b> æ‰åŒ¹é…ï¼‰
```

**æ‰§è¡Œç¤ºä¾‹ï¼š**

```python
import re

text = "<b>bold</b> and <i>italic</i>"
pattern = r'<(\w+)>(.*?)</\1>'

matches = re.finditer(pattern, text)
for m in matches:
    print(f"æ ‡ç­¾: {m.group(1)}, å†…å®¹: {m.group(2)}")

# è¾“å‡ºï¼š
# æ ‡ç­¾: b, å†…å®¹: bold
# æ ‡ç­¾: i, å†…å®¹: italic
```

**ä¸ºä»€ä¹ˆè¦ç”¨ `r'...'` ï¼ˆraw stringï¼‰ï¼Ÿ**

```python
# é”™è¯¯ï¼šä¸ç”¨ r
pattern = '<(\w+)>(.*?)</\1>'
# Pythonä¼šæŠŠ \1 ç†è§£ä¸ºè½¬ä¹‰å­—ç¬¦ï¼ˆæŠ¥é”™ï¼ï¼‰

# æ­£ç¡®ï¼šç”¨ r
pattern = r'<(\w+)>(.*?)</\1>'
# Pythonä¿ç•™ \1 ä½œä¸ºæ­£åˆ™è¡¨è¾¾å¼çš„åå‘å¼•ç”¨
```

---

### ä¸‰ã€è§£å†³æ–¹æ¡ˆè¯¦è§£

#### ä»»åŠ¡1ï¼šåŒ¹é…HTMLæ ‡ç­¾

**æ–¹æ¡ˆ1ï¼šéè´ªå©ªåŒ¹é…**

```python
tag = re.compile('</?(.*?)>')
```

**è§£é‡Šï¼š**

```
</?(.*?)>
â†‘  â†‘   â†‘
|  |   â””â”€ å³å°–æ‹¬å·
|  â””â”€ ç¬¬1ç»„ï¼šæ ‡ç­¾åï¼ˆéè´ªå©ªï¼‰
â””â”€ å¯é€‰çš„æ–œæ ï¼ˆé—­æ ‡ç­¾ç”¨ï¼‰

ä¾‹å­ï¼š
<p>     â†’ åŒ¹é…ï¼Œgroup(1)='p'
</p>    â†’ åŒ¹é…ï¼Œgroup(1)='p'
<title> â†’ åŒ¹é…ï¼Œgroup(1)='title'
```

**é—®é¢˜ï¼š**è¿™ä¸ªæ–¹æ¡ˆä¼šæŠŠå‚æ•°ä¹ŸåŒ…æ‹¬è¿›å»ï¼

```html
<a href="..."> â†’ group(1) = 'a href="..."'  â† ä¸å¥½ï¼
```

---

**æ–¹æ¡ˆ2ï¼šå­—ç¬¦ç±»å–å**

```python
tag = re.compile('</?([^>]+)>')
```

**è§£é‡Šï¼š**

```
</?([^>]+)>
   â†‘    â†‘
   |    â””â”€ 1ä¸ªæˆ–å¤šä¸ª"é>"å­—ç¬¦
   â””â”€ ç¬¬1ç»„

ä¾‹å­ï¼š
<p>            â†’ group(1) = 'p'
<a href="..."> â†’ group(1) = 'a href="..."'
```

**è¿˜æ˜¯æœ‰é—®é¢˜ï¼š**å‚æ•°è¿˜åœ¨é‡Œé¢ï¼

---

**æ–¹æ¡ˆ3ï¼šåˆ†ç¦»æ ‡ç­¾åå’Œå‚æ•°ï¼ˆæœ€ä½³ï¼‰**

```python
tag = re.compile(r'</?(\w+\b)([^>]+)?>')
```

**è¯¦ç»†è§£é‡Šï¼š**

```
r'</?(\w+\b)([^>]+)?>'
    â†‘    â†‘  â†‘     â†‘
    |    |  |     â””â”€ ç¬¬2ç»„ï¼šå‚æ•°éƒ¨åˆ†ï¼ˆå¯é€‰ï¼‰
    |    |  â””â”€ 1ä¸ªæˆ–å¤šä¸ª"é>"å­—ç¬¦
    |    â””â”€ å•è¯è¾¹ç•Œï¼ˆç¡®ä¿æ ‡ç­¾åå®Œæ•´ï¼‰
    â””â”€ ç¬¬1ç»„ï¼šæ ‡ç­¾å

\w+ â† 1ä¸ªæˆ–å¤šä¸ªå•è¯å­—ç¬¦ï¼ˆæ ‡ç­¾åï¼‰
\b  â† å•è¯è¾¹ç•Œï¼ˆWord Boundaryï¼‰
```

**`\b` çš„ä½œç”¨ï¼ˆé‡è¦ï¼ï¼‰ï¼š**

```
\b = å•è¯è¾¹ç•Œï¼ˆWord Boundaryï¼‰

ä½ç½®æ ‡è®°ï¼Œå‡ºç°åœ¨ï¼š
- å•è¯å­—ç¬¦(\w)å’Œéå•è¯å­—ç¬¦ä¹‹é—´
- å­—ç¬¦ä¸²å¼€å¤´/ç»“å°¾

ä¾‹å­ï¼š
"<table border=1>"
  â†‘    â†‘
  table åé¢æ˜¯ç©ºæ ¼
  ç©ºæ ¼ä¸æ˜¯\wï¼Œæ‰€ä»¥è¿™é‡Œæ˜¯\b

\w+\b ç¡®ä¿åªåŒ¹é… "table"ï¼Œä¸åŒ…æ‹¬åé¢çš„ç©ºæ ¼å’Œå‚æ•°
```

**æ‰§è¡Œç¤ºä¾‹ï¼š**

```python
tag = re.compile(r'</?(\w+\b)([^>]+)?>')

html = '<table border=1 cellspacing=0>'
m = tag.search(html)

print(m.group(1))  # 'table'  â† æ ‡ç­¾å
print(m.group(2))  # ' border=1 cellspacing=0'  â† å‚æ•°
```

---

#### ä»»åŠ¡2ï¼šåŒºåˆ†å¼€æ ‡ç­¾å’Œé—­æ ‡ç­¾

**å¼€æ ‡ç­¾ï¼š**

```python
openTag = re.compile(r'<(\w+\b)([^>]+)?>')
```

**é—­æ ‡ç­¾ï¼š**

```python
closeTag = re.compile(r'</(\w+\b)\s*>')
```

**åŒºåˆ«ï¼š**

```
å¼€æ ‡ç­¾ï¼š<(\w+\b)([^>]+)?>
        â†‘
        æ²¡æœ‰æ–œæ è¦æ±‚ï¼Œå¯é€‰çš„å‚æ•°

é—­æ ‡ç­¾ï¼š</(\w+\b)\s*>
         â†‘       â†‘
         å¿…é¡»æœ‰æ–œæ   å¯é€‰çš„ç©ºæ ¼ï¼ˆæœ‰äº›HTMLä¼šå†™æˆ </p  >ï¼‰
```

**æ‰§è¡Œç¤ºä¾‹ï¼š**

```python
openTag = re.compile(r'<(\w+\b)([^>]+)?>')
closeTag = re.compile(r'</(\w+\b)\s*>')

html = '<p>This is <b>bold</b> text.</p>'

# æŸ¥æ‰¾å¼€æ ‡ç­¾
for m in openTag.finditer(html):
    print('OPENTAG:', m.group(1))
    if m.group(2):  # å¦‚æœæœ‰å‚æ•°
        print('  PARAMS:', m.group(2))

# æŸ¥æ‰¾é—­æ ‡ç­¾
for m in closeTag.finditer(html):
    print('CLOSETAG:', m.group(1))

# è¾“å‡ºï¼š
# OPENTAG: p
# OPENTAG: b
# CLOSETAG: b
# CLOSETAG: p
```

---

#### ä»»åŠ¡3ï¼šæå–æ ‡ç­¾å‚æ•°

**å‚æ•°æ ¼å¼ï¼š**

```html
<table border=1 cellspacing=0 cellpadding=8>
       â†‘       â†‘           â†‘
       å‚æ•°1    å‚æ•°2        å‚æ•°3
```

**è§£å†³æ–¹æ¡ˆï¼š**

```python
openTag = re.compile(r'<(\w+\b)([^>]+)?>')

html = '<table border=1 cellspacing=0 cellpadding=8>'
m = openTag.search(html)

if m.group(2):  # å¦‚æœæœ‰å‚æ•°
    params = m.group(2).split()  # æŒ‰ç©ºæ ¼åˆ†å‰²
    for param in params:
        print('PARAM:', param)

# è¾“å‡ºï¼š
# PARAM: border=1
# PARAM: cellspacing=0
# PARAM: cellpadding=8
```

**ä¸ºä»€ä¹ˆç”¨ `.split()`ï¼Ÿ**

```python
# m.group(2) = ' border=1 cellspacing=0 cellpadding=8'
#               â†‘ å¼€å¤´æœ‰ç©ºæ ¼

params = m.group(2).split()
# .split() é»˜è®¤æŒ‰ç©ºæ ¼åˆ†å‰²ï¼Œå¹¶è‡ªåŠ¨å»é™¤é¦–å°¾ç©ºæ ¼
# ç»“æœï¼š['border=1', 'cellspacing=0', 'cellpadding=8']
```

---

#### ä»»åŠ¡4ï¼šåŒ¹é…é…å¯¹çš„å¼€é—­æ ‡ç­¾

**ä½¿ç”¨åå‘å¼•ç”¨ï¼š**

```python
openCloseTagPair = re.compile(r'<(\w+\b)([^>]+)?>(.*?)</\1\s*>')
```

**è¯¦ç»†è§£é‡Šï¼š**

```
r'<(\w+\b)([^>]+)?>(.*?)</\1\s*>'
   â†‘      â†‘        â†‘     â†‘
   |      |        |     â””â”€ åå‘å¼•ç”¨ç¬¬1ç»„ï¼ˆé—­æ ‡ç­¾å¿…é¡»åŒåï¼‰
   |      |        â””â”€ ç¬¬3ç»„ï¼šæ ‡ç­¾ä¹‹é—´çš„å†…å®¹ï¼ˆéè´ªå©ªï¼‰
   |      â””â”€ ç¬¬2ç»„ï¼šå¼€æ ‡ç­¾çš„å‚æ•°ï¼ˆå¯é€‰ï¼‰
   â””â”€ ç¬¬1ç»„ï¼šå¼€æ ‡ç­¾å

ä¾‹å­ï¼š
<b>bold text</b>
ç¬¬1ç»„ï¼šb
ç¬¬2ç»„ï¼šNoneï¼ˆæ²¡æœ‰å‚æ•°ï¼‰
ç¬¬3ç»„ï¼šbold text
\1ï¼šå¿…é¡»æ˜¯ b
```

**æ‰§è¡Œç¤ºä¾‹ï¼š**

```python
pattern = r'<(\w+\b)([^>]+)?>(.*?)</\1\s*>'
html = '<p>This is <b>bold</b> and <i>italic</i> text.</p>'

for m in re.finditer(pattern, html):
    print(f"PAIR [{m.group(1)}]: \"{m.group(3)}\"")

# è¾“å‡ºï¼š
# PAIR [b]: "bold"
# PAIR [i]: "italic"
# PAIR [p]: "This is <b>bold</b> and <i>italic</i> text."
```

**ä¸ºä»€ä¹ˆè¦éè´ªå©ª `.*?`ï¼Ÿ**

```python
html = '<b>first</b> text <b>second</b>'

# è´ªå©ªåŒ¹é… .*
pattern = r'<(\w+)>(.*)</\1>'
# åŒ¹é…ï¼š<b>first</b> text <b>second</b>  â† é”™è¯¯ï¼è·¨è¶Šäº†ä¸¤ä¸ªæ ‡ç­¾

# éè´ªå©ªåŒ¹é… .*?
pattern = r'<(\w+)>(.*?)</\1>'
# åŒ¹é…ï¼š<b>first</b> å’Œ <b>second</b>  â† æ­£ç¡®ï¼
```

---

#### ä»»åŠ¡5ï¼šæå–URL

**HTMLä¸­çš„é“¾æ¥æ ¼å¼ï¼š**

```html
<a href="http://example.com">é“¾æ¥æ–‡æœ¬</a>
<a href=http://example.com>é“¾æ¥æ–‡æœ¬</a>  â† ä¹Ÿå¯ä»¥ä¸ç”¨å¼•å·
```

**æ–¹æ¡ˆ1ï¼šå¸¦å¼•å·çš„URL**

```python
url = re.compile('href=("[^">]+")', re.I)
```

**è§£é‡Šï¼š**

```
href=("[^">]+")
      â†‘    â†‘
      |    â””â”€ å³å¼•å·
      â””â”€ å·¦å¼•å· + 1ä¸ªæˆ–å¤šä¸ª"éå¼•å·ä¸”é>"çš„å­—ç¬¦

[^">]+ â† æ—¢ä¸æ˜¯å¼•å·"ï¼Œä¹Ÿä¸æ˜¯å°–æ‹¬å·>

re.I â† å¿½ç•¥å¤§å°å†™ï¼ˆHREF, Href, hreféƒ½èƒ½åŒ¹é…ï¼‰
```

---

**æ–¹æ¡ˆ2ï¼šä¸å¸¦å¼•å·çš„URL**

```python
url = re.compile('href=([^">\s]+)', re.I)
```

**è§£é‡Šï¼š**

```
href=([^">\s]+)
      â†‘
      1ä¸ªæˆ–å¤šä¸ª"éå¼•å·ã€é>ã€éç©ºæ ¼"çš„å­—ç¬¦

[^">\s]+ â† ä¸æ˜¯å¼•å·ï¼Œä¸æ˜¯>ï¼Œä¸æ˜¯ç©ºæ ¼
```

---

**æ–¹æ¡ˆ3ï¼šä¸¤ç§æƒ…å†µéƒ½æ”¯æŒï¼ˆæœ€ä½³ï¼‰**

```python
url = re.compile(r'href=("[^">]+"|[^">\s]+)', re.I)
```

**è¯¦ç»†è§£é‡Šï¼š**

```
r'href=("[^">]+"|[^">\s]+)'
        â†‘         â†‘
        |         â””â”€ æˆ–ï¼šæ— å¼•å·çš„URL
        â””â”€ å¸¦å¼•å·çš„URL

ç«–çº¿ | è¡¨ç¤º"æˆ–"
å·¦è¾¹ï¼šå¸¦å¼•å·çš„æ ¼å¼  "[^">]+"
å³è¾¹ï¼šæ— å¼•å·çš„æ ¼å¼  [^">\s]+
```

**æ‰§è¡Œç¤ºä¾‹ï¼š**

```python
url = re.compile(r'href=("[^">]+"|[^">\s]+)', re.I)

html1 = '<a href="http://example.com">Link</a>'
html2 = '<a HREF=http://example.com>Link</a>'

print(url.search(html1).group(1))  # "http://example.com"
print(url.search(html2).group(1))  # http://example.com
```

---

#### ä»»åŠ¡6ï¼šåˆ é™¤HTMLæ ‡ç­¾ï¼ˆHTML Strippingï¼‰

**ç›®æ ‡ï¼š**æŠŠHTMLæ ‡ç­¾å…¨éƒ¨åˆ é™¤ï¼Œåªä¿ç•™æ–‡æœ¬

```html
è¾“å…¥ï¼š<p>This is <b>bold</b> text.</p>
è¾“å‡ºï¼šThis is bold text.
```

**ä½¿ç”¨ `.sub()` æ–¹æ³•ï¼š**

```python
tag = re.compile(r'</?(\w+\b)([^>]+)?>')

html = '<p>This is <b>bold</b> text.</p>'
stripped = tag.sub('', html)
print(stripped)  # 'This is bold text.'
```

**`.sub()` è¯¦è§£ï¼š**

```python
pattern.sub(replacement, string)
           â†‘            â†‘
           |            â””â”€ è¦å¤„ç†çš„å­—ç¬¦ä¸²
           â””â”€ æ›¿æ¢æˆä»€ä¹ˆï¼ˆç©ºå­—ç¬¦ä¸²=åˆ é™¤ï¼‰

tag.sub('', html)
        â†‘
        ç©ºå­—ç¬¦ä¸² â† æŠŠæ‰€æœ‰åŒ¹é…çš„æ ‡ç­¾æ›¿æ¢æˆç©º
```

**æ‰§è¡Œè¿‡ç¨‹ï¼š**

```python
html = '<p>This is <b>bold</b> text.</p>'

# æ‰¾åˆ°çš„æ ‡ç­¾ï¼š
# 1. <p>
# 2. <b>
# 3. </b>
# 4. </p>

# æ¯ä¸ªéƒ½æ›¿æ¢æˆ ''

# ç»“æœï¼š'This is bold text.'
```

---

### å››ã€å®Œæ•´ä»£ç ç¤ºä¾‹

```python
import re

# å®šä¹‰æ‰€æœ‰æ­£åˆ™è¡¨è¾¾å¼
tag = re.compile(r'</?(\w+\b)([^>]+)?>')
openTag = re.compile(r'<(\w+\b)([^>]+)?>')
closeTag = re.compile(r'</(\w+\b)\s*>')
openCloseTagPair = re.compile(r'<(\w+\b)([^>]+)?>(.*?)</\1\s*>')
url = re.compile(r'href=("[^">]+"|[^">\s]+)', re.I)

# è¯»å–HTMLæ–‡ä»¶
with open('RGX_DATA.html') as infs:
    linenum = 0
    for line in infs:
        linenum += 1
        if line.strip() == '':
            continue

        print('-' * 100, '[%d]' % linenum)
        print('TEXT:', line, end='')

        # 1. æŸ¥æ‰¾æ‰€æœ‰æ ‡ç­¾
        for m in tag.finditer(line):
            print('** TAG:', m.group(1))

        # 2. æŸ¥æ‰¾å¼€æ ‡ç­¾ï¼ˆå«å‚æ•°ï¼‰
        for m in openTag.finditer(line):
            print('** OPENTAG:', m.group(1))
            if m.group(2):
                for param in m.group(2).split():
                    print('    PARAM:', param)

        # 3. æŸ¥æ‰¾é—­æ ‡ç­¾
        for m in closeTag.finditer(line):
            print('** CLOSETAG:', m.group(1))

        # 4. æŸ¥æ‰¾é…å¯¹çš„æ ‡ç­¾
        for m in openCloseTagPair.finditer(line):
            print("** PAIR [%s]: \"%s\"" % (m.group(1), m.group(3)))

        # 5. æŸ¥æ‰¾URL
        for m in url.finditer(line):
            print('** URL:', m.group(1))

        # 6. åˆ é™¤æ ‡ç­¾
        stripped = tag.sub('', line)
        print('** STRIPPED:', stripped, end='')
```

---

## Part Bï¼šæ–‡æœ¬é¢„å¤„ç†ï¼ˆTwitteræ•°æ®ï¼‰

### ä¸€ã€æ–‡æœ¬é¢„å¤„ç†çš„å¿…è¦æ€§

**é—®é¢˜ï¼š**

```
"LOVe" å’Œ "love" æ˜¯åŒä¸€ä¸ªè¯å—ï¼Ÿ
"food" å’Œ "food." æ˜¯åŒä¸€ä¸ªè¯å—ï¼Ÿ
"I'm" åº”è¯¥ç®—1ä¸ªè¯è¿˜æ˜¯2ä¸ªè¯ï¼Ÿ
```

**è§£å†³æ–¹æ¡ˆï¼š**æ–‡æœ¬é¢„å¤„ç†

```
1. åˆ†è¯ï¼ˆTokenizationï¼‰ï¼šæŠŠå¥å­åˆ‡åˆ†æˆå•è¯
2. å°å†™è½¬æ¢ï¼ˆLowercasingï¼‰ï¼šç»Ÿä¸€å¤§å°å†™
3. æ ‡å‡†åŒ–ï¼ˆNormalizationï¼‰ï¼šç»Ÿä¸€æ ¼å¼
```

---

### äºŒã€åˆ†è¯ï¼ˆTokenizationï¼‰

#### æ–¹æ³•1ï¼šç”¨æ­£åˆ™è¡¨è¾¾å¼è‡ªå·±å†™

**ç®€å•ç‰ˆæœ¬ï¼š**

```python
import re

def tokenise_regex(text):
    pattern = r"\w+(?:'\w+)?|[^\w\s]"
    return re.findall(pattern, text)
```

**è¯¦ç»†è§£é‡Šï¼š**

```
r"\w+(?:'\w+)?|[^\w\s]"
  â†‘           â†‘
  |           â””â”€ æˆ–ï¼šæ ‡ç‚¹ç¬¦å·
  â””â”€ å•è¯ï¼ˆå¯èƒ½åŒ…å«æ’‡å·ï¼‰

\w+(?:'\w+)? â† åŒ¹é…å•è¯ï¼Œå¦‚ "don't", "it's"
|            â† æˆ–
[^\w\s]      â† åŒ¹é…æ ‡ç‚¹ç¬¦å·ï¼ˆæ—¢ä¸æ˜¯å•è¯å­—ç¬¦ä¹Ÿä¸æ˜¯ç©ºæ ¼ï¼‰
```

**`(?:...)` æ˜¯ä»€ä¹ˆï¼Ÿ**

```
(?:...) â† éæ•è·ç»„ï¼ˆNon-capturing groupï¼‰

å’Œ (...) çš„åŒºåˆ«ï¼š
(...)   â† æ•è·ç»„ï¼Œä¼šè¢« group(1) æå–
(?:...) â† éæ•è·ç»„ï¼Œä¸ä¼šè¢«æå–ï¼Œåªç”¨äºåˆ†ç»„

ä¸ºä»€ä¹ˆç”¨éæ•è·ç»„ï¼Ÿ
å› ä¸ºæˆ‘ä»¬åªæƒ³åŒ¹é…æ¨¡å¼ï¼Œä¸éœ€è¦å•ç‹¬æå–è¿™éƒ¨åˆ†
```

**æ‰§è¡Œç¤ºä¾‹ï¼š**

```python
text = "He says I'm depressed most of the time."
tokens = tokenise_regex(text)
print(tokens)

# è¾“å‡ºï¼š
# ['He', 'says', 'I', "'", 'm', 'depressed', 'most', 'of', 'the', 'time', '.']
```

**å¤„ç†æ’‡å·ï¼š**

```python
pattern = r"\w+(?:'\w+)?|[^\w\s]"

# "I'm"
\w+      â† åŒ¹é… 'I'
(?:'\w+)?  â† å°è¯•åŒ¹é… "'m"
ç»“æœï¼š'I' å’Œ "'m" åˆ†å¼€

# "don't"
\w+      â† åŒ¹é… 'don'
(?:'\w+)?  â† åŒ¹é… "'t"
ç»“æœï¼š'don' å’Œ "'t" åˆ†å¼€
```

**é—®é¢˜ï¼š**æ’‡å·è¿˜æ˜¯è¢«åˆ†å¼€äº†ï¼

---

**æ”¹è¿›ç‰ˆæœ¬ï¼š**

```python
pattern = r"\w+(?:'\w+)?|[^\w\s]"

# æ›´å¥½çš„ç‰ˆæœ¬ï¼š
pattern = r"\w+(?:'\w+)*|[^\w\s]"
#             â†‘ æ”¹æˆ * ï¼ˆ0æ¬¡æˆ–å¤šæ¬¡ï¼‰
```

ä½†å®é™…ä¸ŠåŸç‰ˆå°±èƒ½å·¥ä½œï¼š

```python
text = "I'm"

# åŒ¹é…è¿‡ç¨‹ï¼š
\w+       â† åŒ¹é… 'I'
(?:'\w+)? â† å°è¯•åŒ¹é… "'m"

ä½†é—®é¢˜æ˜¯ï¼š\w ä¹Ÿèƒ½åŒ¹é… m
æ‰€ä»¥ \w+ ä¼šè´ªå©ªåœ°åŒ¹é… 'I', 'm' éƒ½åŒ¹é…äº†
(?:'\w+)? å°±æ²¡æœºä¼šåŒ¹é…æ’‡å·äº†

æ­£ç¡®çš„patternåº”è¯¥æ›´ç²¾ç¡®ï¼š
r"[a-zA-Z]+(?:'[a-zA-Z]+)?|[^\w\s]"
```

---

#### æ–¹æ³•2ï¼šç”¨NLTKçš„æ­£åˆ™è¡¨è¾¾å¼åˆ†è¯å™¨

**NLTKæä¾›çš„å¤æ‚patternï¼š**

```python
import nltk

pattern = r'''(?x)          # å…è®¸verboseæ¨¡å¼ï¼ˆå¯ä»¥å†™æ³¨é‡Šï¼‰
        (?:[A-Z]\.)+        # ç¼©å†™è¯ï¼Œå¦‚ U.S.A.
      | \w+(?:-\w+)*        # å¸¦è¿å­—ç¬¦çš„è¯ï¼Œå¦‚ San Francisco-based
      | \$?\d+(?:\.\d+)?%?  # è´§å¸å’Œç™¾åˆ†æ¯”ï¼Œå¦‚ $12.40, 82%
      | \.\.\.              # çœç•¥å·
      | [][.,;"'?():_`-]    # æ ‡ç‚¹ç¬¦å·
    '''

tokens = nltk.regexp_tokenize(text, pattern)
```

**è¯¦ç»†è§£é‡Šï¼š**

**`(?x)` æ¨¡å¼ï¼š**
```
(?x) â† verboseæ¨¡å¼ï¼Œå…è®¸ï¼š
  - æ­£åˆ™è¡¨è¾¾å¼ä¸­çš„ç©ºæ ¼è¢«å¿½ç•¥
  - å¯ä»¥å†™æ³¨é‡Šï¼ˆ# ...ï¼‰
  - è®©å¤æ‚çš„patternæ›´æ˜“è¯»
```

**å„éƒ¨åˆ†è§£é‡Šï¼š**

```python
(?:[A-Z]\.)+  â† ç¼©å†™è¯
# U.S.A. â†’ åŒ¹é…
# [A-Z]  â† å¤§å†™å­—æ¯
# \.     â† ç‚¹å·
# +      â† 1æ¬¡æˆ–å¤šæ¬¡

\w+(?:-\w+)*  â† å¸¦è¿å­—ç¬¦çš„è¯
# San Francisco-based â†’ åŒ¹é…æ•´ä¸ª
# \w+       â† ç¬¬ä¸€éƒ¨åˆ†å•è¯
# (?:-\w+)* â† 0æ¬¡æˆ–å¤šæ¬¡çš„ "-å•è¯"

\$?\d+(?:\.\d+)?%?  â† æ•°å­—ã€è´§å¸ã€ç™¾åˆ†æ¯”
# $12.40 â†’ åŒ¹é…
# 82%    â†’ åŒ¹é…
# \$?         â† å¯é€‰çš„ç¾å…ƒç¬¦å·
# \d+         â† 1ä¸ªæˆ–å¤šä¸ªæ•°å­—
# (?:\.\d+)?  â† å¯é€‰çš„å°æ•°éƒ¨åˆ†
# %?          â† å¯é€‰çš„ç™¾åˆ†å·

\.\.\.  â† çœç•¥å·
# ...  â†’ åŒ¹é…

[][.,;"'?():_`-]  â† æ ‡ç‚¹ç¬¦å·
# å„ç§æ ‡ç‚¹ï¼ŒåŒ…æ‹¬æ–¹æ‹¬å·
```

**æ‰§è¡Œç¤ºä¾‹ï¼š**

```python
text = "The U.S.A. doesn't charge $10.5"
tokens = nltk.regexp_tokenize(text, pattern)
print(tokens)

# è¾“å‡ºï¼š
# ['The', 'U.S.A.', 'does', "n't", 'charge', '$10.5']
```

---

#### æ–¹æ³•3ï¼šç”¨NLTKçš„å†…ç½®åˆ†è¯å™¨ï¼ˆæœ€ç®€å•ï¼‰

```python
import nltk

text = "He says I'm depressed most of the time."
tokens = nltk.word_tokenize(text)
print(tokens)

# è¾“å‡ºï¼š
# ['He', 'says', 'I', "'m", 'depressed', 'most', 'of', 'the', 'time', '.']
```

**ä¼˜ç‚¹ï¼š**
- ç®€å•æ˜“ç”¨
- å¤„ç†äº†å¾ˆå¤šè¾¹ç¼˜æƒ…å†µ
- ä¸éœ€è¦è‡ªå·±å†™æ­£åˆ™è¡¨è¾¾å¼

---

### ä¸‰ã€å°å†™è½¬æ¢ï¼ˆLowercasingï¼‰

#### æ–¹æ³•1ï¼šç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢

```python
def lowercase_regex(text):
    return re.sub(r"[A-Z]", lambda x: x.group(0).lower(), text)
```

**è¯¦ç»†è§£é‡Šï¼š**

```python
re.sub(r"[A-Z]", lambda x: x.group(0).lower(), text)
       â†‘         â†‘                              â†‘
       |         |                              â””â”€ åŸæ–‡æœ¬
       |         â””â”€ æ›¿æ¢å‡½æ•°ï¼šæŠŠåŒ¹é…çš„å­—ç¬¦è½¬å°å†™
       â””â”€ patternï¼šåŒ¹é…å¤§å†™å­—æ¯

lambda x: x.group(0).lower()
       â†‘  â†‘         â†‘
       |  |         â””â”€ è½¬å°å†™
       |  â””â”€ è·å–åŒ¹é…çš„å­—ç¬¦
       â””â”€ åŒ¹é…å¯¹è±¡
```

**æ‰§è¡Œè¿‡ç¨‹ï¼š**

```python
text = "He Says HELLO"

# åŒ¹é…åˆ°ï¼šH, S, H, E, L, L, O
# æ¯ä¸ªéƒ½è°ƒç”¨ lambda å‡½æ•°

# H â†’ lambda(match_H) â†’ match_H.group(0).lower() â†’ 'h'
# S â†’ lambda(match_S) â†’ match_S.group(0).lower() â†’ 's'
# ...

# ç»“æœï¼š"he says hello"
```

---

#### æ–¹æ³•2ï¼šç”¨Pythonå†…ç½®æ–¹æ³•ï¼ˆæ›´ç®€å•ï¼‰

```python
text = "He Says HELLO"
lowercased = text.lower()
print(lowercased)  # "he says hello"
```

---

### å››ã€Twitterç‰¹æ®Šå…ƒç´ å¤„ç†

**Twitteræ–‡æœ¬çš„ç‰¹ç‚¹ï¼š**

```
@username  â† æåˆ°ç”¨æˆ·
#hashtag   â† è¯é¢˜æ ‡ç­¾
:)         â† è¡¨æƒ…ç¬¦å·ï¼ˆæ–‡æœ¬ï¼‰
ğŸ˜Š         â† è¡¨æƒ…ç¬¦å·ï¼ˆemojiå›¾åƒï¼‰
```

**ä¸ºä»€ä¹ˆè¦å¤„ç†ï¼Ÿ**

```
åŸæ–‡æœ¬ï¼š
"I love @Apple! #iPhone :)"
"I love @Google! #Pixel :)"

åˆ†è¯åï¼š
['I', 'love', '@Apple', '!', '#iPhone', ':)']
['I', 'love', '@Google', '!', '#Pixel', ':)']

é—®é¢˜ï¼š@Apple å’Œ @Google è¢«è®¤ä¸ºæ˜¯ä¸åŒçš„è¯
     #iPhone å’Œ #Pixel ä¹Ÿæ˜¯ä¸åŒçš„è¯

ä½†å®é™…ä¸Šï¼Œæˆ‘ä»¬å¯èƒ½åªå…³å¿ƒï¼š
- æœ‰æ²¡æœ‰æåˆ°ç”¨æˆ·ï¼ˆä¸ç®¡æ˜¯è°ï¼‰
- æœ‰æ²¡æœ‰ç”¨è¯é¢˜æ ‡ç­¾ï¼ˆä¸ç®¡ä»€ä¹ˆè¯é¢˜ï¼‰
- æƒ…æ„Ÿå¦‚ä½•ï¼ˆè¡¨æƒ…ç¬¦å·ï¼‰
```

**è§£å†³æ–¹æ¡ˆï¼šæ ‡å‡†åŒ–**

```
@Apple  â†’ <MENTIONS>
@Google â†’ <MENTIONS>
#iPhone â†’ <HASHTAGS>
#Pixel  â†’ <HASHTAGS>
:)      â†’ <EMOTICONS>
```

---

#### å®ç°ä»£ç 

```python
def preprocess_tweet(text, include_emojis=False):
    # Pattern 1: @mentions
    mention_pattern = r"@[a-zA-Z0-9_]{0,15}"

    # Pattern 2: #hashtags
    hashtag_pattern = r"#(\w+)"

    # Pattern 3: æ–‡æœ¬è¡¨æƒ…ç¬¦å·
    emoticon_pattern = r"(\:\w+\:|\<[\/\\]?3|[\(\)\\\D|\*\$][\-\^]?[\:\;\=]|[\:\;\=B8][\-\^]?[3DOPp\@\$\*\\\)\(\/\|])(?=\s|[\!\.\?]|$)"

    # æ›¿æ¢ï¼ˆæ³¨æ„é¡ºåºå¾ˆé‡è¦ï¼ï¼‰
    processed = re.sub(emoticon_pattern, "<EMOTICONS>", text)
    processed = re.sub(hashtag_pattern, "<HASHTAGS>", processed)
    processed = re.sub(mention_pattern, "<MENTIONS>", processed)

    return processed
```

**è¯¦ç»†è§£é‡Šï¼š**

**Pattern 1: @mentions**

```python
mention_pattern = r"@[a-zA-Z0-9_]{0,15}"

@              â† @ ç¬¦å·
[a-zA-Z0-9_]   â† å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿
{0,15}         â† 0åˆ°15ä¸ªå­—ç¬¦ï¼ˆTwitterç”¨æˆ·åé™åˆ¶ï¼‰

ä¾‹å­ï¼š
@username123 â†’ åŒ¹é…
@a_b_c       â†’ åŒ¹é…
```

---

**Pattern 2: #hashtags**

```python
hashtag_pattern = r"#(\w+)"

#     â† # ç¬¦å·
(\w+) â† 1ä¸ªæˆ–å¤šä¸ªå•è¯å­—ç¬¦ï¼ˆæ•è·ç»„ï¼‰

ä¾‹å­ï¼š
#iPhone  â†’ åŒ¹é…ï¼Œgroup(1)='iPhone'
#AI2023  â†’ åŒ¹é…ï¼Œgroup(1)='AI2023'
```

**ä¸ºä»€ä¹ˆç”¨æ•è·ç»„ `(\w+)`ï¼Ÿ**

```python
# ä¸ç”¨æ•è·ç»„ï¼š
re.sub(r"#\w+", "<HASHTAGS>", text)
# ç»“æœï¼šå®Œå…¨æ›¿æ¢ #iPhone â†’ <HASHTAGS>

# ç”¨æ•è·ç»„ï¼š
re.sub(r"#(\w+)", "<HASHTAGS>", text)
# ç»“æœï¼šä¹Ÿæ˜¯å®Œå…¨æ›¿æ¢

# å®é™…ä¸Šè¿™é‡Œæ•è·ç»„ä¸å¿…è¦ï¼Œä½†ä¿ç•™ä¸‹æ¥æ˜¯ä¸ºäº†ï¼š
# 1. å¯èƒ½ä»¥åéœ€è¦è®¿é—®hashtagå†…å®¹
# 2. ä»£ç æ›´æ¸…æ™°
```

---

**Pattern 3: æ–‡æœ¬è¡¨æƒ…ç¬¦å·ï¼ˆéå¸¸å¤æ‚ï¼ï¼‰**

```python
emoticon_pattern = r"(\:\w+\:|\<[\/\\]?3|[\(\)\\\D|\*\$][\-\^]?[\:\;\=]|[\:\;\=B8][\-\^]?[3DOPp\@\$\*\\\)\(\/\|])(?=\s|[\!\.\?]|$)"
```

è¿™ä¸ªå¤ªå¤æ‚ï¼Œæˆ‘ä»¬åˆ†è§£ï¼š

```python
# ç®€åŒ–ç‰ˆï¼š
emoticon_pattern = r"(\:\w+\:)"  # åªåŒ¹é… :smile:
                 + r"|"          # æˆ–
                 + r"[\:\;\=][\)\(]"  # :) :( =) =(
```

**åˆ†è§£è¯¦ç»†ç‰ˆæœ¬ï¼š**

```
ç¬¬1éƒ¨åˆ†ï¼š\:\w+\:
  åŒ¹é…ï¼š:smile: :joy: :cry:

ç¬¬2éƒ¨åˆ†ï¼š\<[\/\\]?3
  åŒ¹é…ï¼š<3 </3 <\3ï¼ˆå¿ƒå½¢ï¼‰

ç¬¬3éƒ¨åˆ†ï¼š[\(\)\\\D|\*\$][\-\^]?[\:\;\=]
  åŒ¹é…å„ç§å¤æ‚è¡¨æƒ…ï¼Œå¦‚ :-)  ;)  =(

ç¬¬4éƒ¨åˆ†ï¼š[\:\;\=B8][\-\^]?[3DOPp\@\$\*\\\)\(\/\|]
  åŒ¹é…æ›´å¤šå˜ä½“

æœ€åï¼š(?=\s|[\!\.\?]|$)
  â† å‰ç»æ–­è¨€ï¼ˆLookahead assertionï¼‰
  ç¡®ä¿è¡¨æƒ…ç¬¦å·åé¢æ˜¯ç©ºæ ¼ã€æ ‡ç‚¹æˆ–ç»“å°¾
```

**å‰ç»æ–­è¨€ `(?=...)` è§£é‡Šï¼š**

```
(?=...) â† æ­£å‘å‰ç»ï¼ˆPositive lookaheadï¼‰

æ„æ€ï¼šåé¢å¿…é¡»åŒ¹é…...ï¼Œä½†ä¸æ¶ˆè€—å­—ç¬¦

ä¾‹å­ï¼š
text = "happy:)sad"

pattern = r":\)(?=\s)"
# ä¸åŒ¹é…ï¼å› ä¸º :) åé¢ä¸æ˜¯ç©ºæ ¼

text = "happy:) sad"
pattern = r":\)(?=\s)"
# åŒ¹é…ï¼å› ä¸º :) åé¢æ˜¯ç©ºæ ¼
# ä½†åŒ¹é…çš„åªæ˜¯ :)ï¼Œä¸åŒ…æ‹¬ç©ºæ ¼
```

---

**æ›¿æ¢é¡ºåºä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ**

```python
text = "Love @user #tag :)"

# é”™è¯¯é¡ºåº1ï¼šå…ˆæ›¿æ¢mentions
processed = re.sub(mention_pattern, "<MENTIONS>", text)
# ç»“æœï¼š"Love <MENTIONS> #tag :)"
processed = re.sub(hashtag_pattern, "<HASHTAGS>", processed)
# ç»“æœï¼š"Love <MENTIONS> <HASHTAGS> :)"

# é—®é¢˜ï¼šå¦‚æœhashtag patternå†™é”™ï¼Œå¯èƒ½åŒ¹é…åˆ° <MENTIONS> çš„ä¸€éƒ¨åˆ†

# æ¨èé¡ºåºï¼šä»æœ€ç‰¹æ®Šåˆ°æœ€ä¸€èˆ¬
# 1. emoticonsï¼ˆæœ€ç‰¹æ®Šï¼Œç¬¦å·å®¹æ˜“å’Œå…¶ä»–å†²çªï¼‰
# 2. hashtags
# 3. mentions
```

---

#### Emojiå¤„ç†ï¼ˆå¯é€‰æŒ‘æˆ˜ï¼‰

**Emojiæ˜¯ä»€ä¹ˆï¼Ÿ**

```
ğŸ˜Š â† è¿™æ˜¯emojiï¼ˆUnicodeå­—ç¬¦ï¼‰
:) â† è¿™æ˜¯emoticonï¼ˆæ–‡æœ¬ç¬¦å·ï¼‰
```

**åŒ¹é…Emojiçš„patternï¼š**

```python
emoji_pattern = re.compile(pattern = "["
    u"\U0001F600-\U0001F64F"  # Emoticons range
    u"\U0001F300-\U0001F5FF"  # Symbols & pictographs
    u"\U0001FAC0-\U0001FaFF"  # Extended symbols
    u"\U00012600-\U000126FF"  # Miscellaneous
    u"\U00002700-\U000027BF"  # Dingbats
    u"\U0001F100-\U0001F1FF"  # Alphanumeric supplement
    u"\U0001F680-\U0001F6FF"  # Transport & map
    u"\U0001F1E0-\U0001F1FF"  # Flags
    u"\U00002190-\U000021FF"  # Arrows
    "]+", flags = re.UNICODE)
```

**UnicodeèŒƒå›´è§£é‡Šï¼š**

```
\U0001F600-\U0001F64F
  â†‘        â†‘
  |        â””â”€ ç»“æŸç ç‚¹
  â””â”€ å¼€å§‹ç ç‚¹

U+1F600 = ğŸ˜€ (grinning face)
U+1F64F = ğŸ™ (folded hands)

è¿™ä¸ªèŒƒå›´åŒ…å«æ‰€æœ‰"è„¸éƒ¨è¡¨æƒ…"emoji
```

**ä½¿ç”¨ï¼š**

```python
text = "I love Python! ğŸ˜ŠğŸ‰"
processed = emoji_pattern.sub("<EMOJIS>", text)
print(processed)
# "I love Python! <EMOJIS><EMOJIS>"
```

---

### äº”ã€ç±»å‹-æ ‡è®°æ¯”ç‡ï¼ˆType-Token Ratio, TTRï¼‰

#### æ¦‚å¿µ

**Typesï¼ˆç±»å‹ï¼‰ï¼š**ä¸åŒå•è¯çš„æ•°é‡ï¼ˆè¯æ±‡é‡ï¼‰

```python
text = "the cat and the dog"
tokens = ['the', 'cat', 'and', 'the', 'dog']

types = set(tokens)  # {'the', 'cat', 'and', 'dog'}
num_types = len(types)  # 4
```

**Tokensï¼ˆæ ‡è®°ï¼‰ï¼š**æ‰€æœ‰å•è¯çš„æ€»æ•°

```python
num_tokens = len(tokens)  # 5
```

**TTRï¼ˆç±»å‹-æ ‡è®°æ¯”ç‡ï¼‰ï¼š**

```
TTR = Types / Tokens = 4 / 5 = 0.8
```

**æ„ä¹‰ï¼š**

```
é«˜TTRï¼ˆæ¥è¿‘1ï¼‰ï¼šè¯æ±‡ä¸°å¯Œï¼Œå¾ˆå°‘é‡å¤
  ä¾‹å¦‚ï¼šå­¦æœ¯è®ºæ–‡

ä½TTRï¼ˆæ¥è¿‘0ï¼‰ï¼šè¯æ±‡ç®€å•ï¼Œå¤§é‡é‡å¤
  ä¾‹å¦‚ï¼šå„¿ç«¥è¯»ç‰©
```

---

#### å®ç°ä»£ç 

```python
def count_types_and_tokens(tweets_list):
    types = set()
    tokens = []

    for tweet in tweets_list:
        for token in tweet:
            # åªç»Ÿè®¡åŒ…å«å­—æ¯æˆ–æ•°å­—çš„tokenï¼ˆæ’é™¤æ ‡ç‚¹ï¼‰
            if re.search("[a-zA-Z0-9]+", token):
                types.add(token)
                tokens.append(token)

    return len(types), len(tokens)
```

**è¯¦ç»†è§£é‡Šï¼š**

```python
types = set()  # é›†åˆï¼Œè‡ªåŠ¨å»é‡
tokens = []    # åˆ—è¡¨ï¼Œä¿ç•™é‡å¤

for tweet in tweets_list:
    # tweets_listæ˜¯åˆ—è¡¨çš„åˆ—è¡¨
    # ä¾‹å¦‚ï¼š[['I', 'love', 'Python'], ['Python', 'is', 'great']]

    for token in tweet:
        # æ£€æŸ¥tokenæ˜¯å¦åŒ…å«å­—æ¯æˆ–æ•°å­—
        if re.search("[a-zA-Z0-9]+", token):
            types.add(token)      # é›†åˆè‡ªåŠ¨å»é‡
            tokens.append(token)  # åˆ—è¡¨ä¿ç•™æ‰€æœ‰
```

**ä¸ºä»€ä¹ˆè¦æ£€æŸ¥ `[a-zA-Z0-9]+`ï¼Ÿ**

```python
tokens = ['I', 'love', 'Python', '.', '!']

# ä¸æ£€æŸ¥ï¼š
types = {'I', 'love', 'Python', '.', '!'}  # 5ä¸ªtypes
tokens_count = 5
TTR = 5/5 = 1.0  â† ä½†æ ‡ç‚¹ä¸ç®—"è¯æ±‡"ï¼

# æ£€æŸ¥åï¼š
types = {'I', 'love', 'Python'}  # 3ä¸ªtypes
tokens_count = 3
TTR = 3/3 = 1.0  â† æ›´å‡†ç¡®
```

---

#### è®¡ç®—TTR

```python
def print_config_ttr(config_string, processed_tweets):
    num_types, num_tokens = count_types_and_tokens(processed_tweets)
    ttr = round(num_types / num_tokens, 3)
    print(f"{config_string}: {ttr} ({num_types} types, {num_tokens} tokens)")
```

**æ‰§è¡Œç¤ºä¾‹ï¼š**

```python
tweets = [
    "I love Python",
    "I love coding",
    "Python is great"
]

# é…ç½®1ï¼šæ— é¢„å¤„ç†
tweets_split = [tweet.split(" ") for tweet in tweets]
print_config_ttr("No preprocessing", tweets_split)

# é…ç½®2ï¼šåˆ†è¯
tweets_tokenized = [nltk.word_tokenize(tweet) for tweet in tweets]
print_config_ttr("Tokenised", tweets_tokenized)

# é…ç½®3ï¼šåˆ†è¯ + å°å†™
tweets_lower = [nltk.word_tokenize(tweet.lower()) for tweet in tweets]
print_config_ttr("Tokenised + lowercased", tweets_lower)

# è¾“å‡ºå¯èƒ½æ˜¯ï¼š
# No preprocessing: 0.778 (7 types, 9 tokens)
# Tokenised: 0.778 (7 types, 9 tokens)
# Tokenised + lowercased: 0.714 (5 types, 7 tokens)
```

**ä¸ºä»€ä¹ˆTTRä¼šä¸‹é™ï¼Ÿ**

```python
# é…ç½®1ï¼šæ— é¢„å¤„ç†
tokens = ['I', 'love', 'Python', 'I', 'love', 'coding', 'Python', 'is', 'great']
types = {'I', 'love', 'Python', 'coding', 'is', 'great'}  # 6ä¸ª
# ï¼ˆå»æ‰æ ‡ç‚¹åï¼‰
TTR = 6 / 9 = 0.667

# é…ç½®3ï¼šå°å†™
tokens = ['i', 'love', 'python', 'i', 'love', 'coding', 'python', 'is', 'great']
types = {'i', 'love', 'python', 'coding', 'is', 'great'}  # 6ä¸ª
# 'I' å’Œ 'i' åˆå¹¶äº†ï¼'Python' å’Œ 'python' åˆå¹¶äº†ï¼
# ä½†åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼ŒåŸæœ¬éƒ½æ˜¯å°å†™ï¼Œæ‰€ä»¥typesæ•°é‡ä¸å˜

# ä½†å¦‚æœæœ‰ï¼š
# "I love Python" å’Œ "i love python"
# ä¸å°å†™ï¼štypes = {'I', 'love', 'Python', 'i', 'python'}  # 5ä¸ª
# å°å†™åï¼štypes = {'i', 'love', 'python'}  # 3ä¸ª
# typeså‡å°‘ â†’ TTRä¸‹é™
```

**å¯¹ä¸‹æ¸¸ä»»åŠ¡çš„å½±å“ï¼š**

```
TTRä¸‹é™ = è¯æ±‡é‡å‡å°‘ = æ¯ä¸ªè¯å‡ºç°é¢‘ç‡å¢åŠ 

ä¼˜ç‚¹ï¼š
1. æ›´å®¹æ˜“æ‰¾åˆ°æ¨¡å¼
2. ç¨€ç–æ€§é™ä½
3. æ¨¡å‹è®­ç»ƒæ›´ç¨³å®š

ç¼ºç‚¹ï¼š
1. å¯èƒ½ä¸¢å¤±ä¿¡æ¯ï¼ˆå¦‚ 'Apple' å…¬å¸ vs 'apple' æ°´æœï¼‰
2. æƒ…æ„Ÿåˆ†æå¯èƒ½å—å½±å“ï¼ˆ'LOVE' vs 'love' å¼ºåº¦ä¸åŒï¼‰
```

---

### å…­ã€å®Œæ•´æ‰§è¡Œæµç¨‹ç¤ºä¾‹

**è¾“å…¥æ•°æ®ï¼š**

```python
tweets = [
    "He says I'm depressed most of the time. #sad",
    "For the first time I get to see @username actually being hateful! it was beautiful:)",
    '"The San Francisco-based restaurant" they said, "doesn\'t charge $10.5"'
]
```

---

**æ­¥éª¤1ï¼šåŸå§‹åˆ†è¯**

```python
for tweet in tweets:
    tokens = tweet.split(" ")
    print(tokens)

# è¾“å‡ºï¼š
# ['He', 'says', "I'm", 'depressed', 'most', 'of', 'the', 'time.', '#sad']
# ['For', 'the', 'first', 'time', 'I', 'get', 'to', 'see', '@username', ...]
```

**é—®é¢˜ï¼š**
- `"I'm"` æ²¡æœ‰åˆ†å¼€
- `"time."` åŒ…å«æ ‡ç‚¹
- `"#sad"` åŒ…å«#å·

---

**æ­¥éª¤2ï¼šç”¨NLTKåˆ†è¯**

```python
for tweet in tweets:
    tokens = nltk.word_tokenize(tweet)
    print(tokens)

# è¾“å‡ºï¼š
# ['He', 'says', 'I', "'m", 'depressed', 'most', 'of', 'the', 'time', '.', '#', 'sad']
# ...
```

**æ”¹è¿›ï¼š**
- `"I'm"` åˆ†æˆäº† `'I'` å’Œ `"'m"`
- æ ‡ç‚¹ç‹¬ç«‹äº†

---

**æ­¥éª¤3ï¼šå°å†™ + åˆ†è¯**

```python
for tweet in tweets:
    lowercased = tweet.lower()
    tokens = nltk.word_tokenize(lowercased)
    print(tokens)

# è¾“å‡ºï¼š
# ['he', 'says', 'i', "'m", 'depressed', 'most', 'of', 'the', 'time', '.', '#', 'sad']
```

---

**æ­¥éª¤4ï¼šé¢„å¤„ç† + å°å†™ + åˆ†è¯**

```python
for tweet in tweets:
    lowercased = tweet.lower()
    preprocessed = preprocess_tweet(lowercased)
    tokens = nltk.word_tokenize(preprocessed)
    print(tokens)

# è¾“å‡ºï¼š
# ['he', 'says', 'i', "'m", 'depressed', 'most', 'of', 'the', 'time', '.', '<HASHTAGS>']
# ['for', 'the', 'first', 'time', 'i', 'get', 'to', 'see', '<MENTIONS>', 'actually', 'being', 'hateful', '!', 'it', 'was', 'beautiful', '<EMOTICONS>']
# ['"', 'the', 'san', 'francisco-based', 'restaurant', '"', 'they', 'said', ',', '"', 'does', "n't", 'charge', '$', '10.5', '"']
```

**æ”¹è¿›ï¼š**
- `#sad` â†’ `<HASHTAGS>`
- `@username` â†’ `<MENTIONS>`
- `:)` â†’ `<EMOTICONS>`

---

**æ­¥éª¤5ï¼šè®¡ç®—TTR**

```python
# é…ç½®1ï¼šæ— é¢„å¤„ç†
tweets_split = [tweet.split(" ") for tweet in tweets]
num_types, num_tokens = count_types_and_tokens(tweets_split)
print(f"TTR: {num_types / num_tokens:.3f}")

# é…ç½®4ï¼šå®Œæ•´é¢„å¤„ç†
processed_tweets = [
    nltk.word_tokenize(preprocess_tweet(tweet.lower()))
    for tweet in tweets
]
num_types, num_tokens = count_types_and_tokens(processed_tweets)
print(f"TTR: {num_types / num_tokens:.3f}")
```

**ç»“æœåˆ†æï¼š**

```
æ— é¢„å¤„ç†ï¼š
  types = å¾ˆå¤šï¼ˆæ¯ä¸ª@username, #hashtagéƒ½ç®—ä¸åŒçš„è¯ï¼‰
  TTR = é«˜

å®Œæ•´é¢„å¤„ç†ï¼š
  types = è¾ƒå°‘ï¼ˆæ‰€æœ‰@usernameéƒ½å˜æˆ<MENTIONS>ï¼‰
  TTR = ä½

TTRé™ä½æ˜¯å¥½äº‹ï¼
â†’ è¯æ±‡é‡å‡å°‘
â†’ æ¯ä¸ªè¯å‡ºç°é¢‘ç‡å¢åŠ 
â†’ æœºå™¨å­¦ä¹ æ¨¡å‹æ›´å®¹æ˜“å­¦ä¹ æ¨¡å¼
```

---

## ä¸ƒã€çº¸ç¬”è€ƒè¯•é‡ç‚¹

### å¿…é¡»æŒæ¡

#### 1. âœ… **è´ªå©ª vs éè´ªå©ªåŒ¹é…**

```
è´ªå©ªï¼š.*   â†’ å°½å¯èƒ½å¤šåŒ¹é…
éè´ªå©ªï¼š.*? â†’ å°½å¯èƒ½å°‘åŒ¹é…

<p><b>text</b>
  .*  åŒ¹é…ï¼šp><b>text</b
  .*? åŒ¹é…ï¼šp
```

#### 2. âœ… **å­—ç¬¦ç±»å–å `[^...]`**

```
[^>]+ â†’ åŒ¹é…1ä¸ªæˆ–å¤šä¸ª"é>"å­—ç¬¦
[^">\s]+ â†’ åŒ¹é…1ä¸ªæˆ–å¤šä¸ª"éå¼•å·ã€é>ã€éç©ºæ ¼"å­—ç¬¦
```

#### 3. âœ… **åå‘å¼•ç”¨ `\1`, `\2`**

```
r'<(\w+)>(.*?)</\1>'
   â†‘           â†‘
   ç¬¬1ç»„      å¿…é¡»åŒ¹é…ç¬¬1ç»„çš„å†…å®¹

<b>text</b> â†’ åŒ¹é…ï¼ˆå¼€é—­æ ‡ç­¾éƒ½æ˜¯bï¼‰
<b>text</i> â†’ ä¸åŒ¹é…ï¼ˆå¼€é—­æ ‡ç­¾ä¸åŒï¼‰
```

#### 4. âœ… **å‰ç»æ–­è¨€ `(?=...)`**

```
(?=...) â†’ åé¢å¿…é¡»æ˜¯...ï¼Œä½†ä¸æ¶ˆè€—å­—ç¬¦
(?!...) â†’ åé¢ä¸èƒ½æ˜¯...

pattern = r":\)(?=\s)"
"happy:) " â†’ åŒ¹é…ï¼ˆåé¢æ˜¯ç©ºæ ¼ï¼‰
"happy:)." â†’ ä¸åŒ¹é…ï¼ˆåé¢æ˜¯ç‚¹å·ï¼‰
```

#### 5. âœ… **éæ•è·ç»„ `(?:...)`**

```
(...)   â†’ æ•è·ç»„ï¼Œå¯ç”¨group(1)æå–
(?:...) â†’ éæ•è·ç»„ï¼Œåªç”¨äºåˆ†ç»„ï¼Œä¸æå–

r"\w+(?:'\w+)?"
      â†‘
      éæ•è·ï¼Œä¸ä¼šè¢«group(1)æå–
```

#### 6. âœ… **TTRè®¡ç®—**

```
TTR = Types / Tokens

Types = ä¸åŒå•è¯æ•°é‡
Tokens = æ€»å•è¯æ•°é‡

ä¾‹å­ï¼š
"the cat and the dog"
Types = 4ï¼ˆthe, cat, and, dogï¼‰
Tokens = 5
TTR = 4/5 = 0.8
```

#### 7. âœ… **é¢„å¤„ç†å¯¹TTRçš„å½±å“**

```
é¢„å¤„ç†æ­¥éª¤è¶Šå¤š â†’ Typesè¶Šå°‘ â†’ TTRè¶Šä½

åŸå› ï¼š
1. å°å†™è½¬æ¢ï¼š'The' å’Œ 'the' åˆå¹¶
2. æ ‡å‡†åŒ–ï¼š@user1, @user2 éƒ½å˜æˆ <MENTIONS>
```

---

### å¯èƒ½çš„è€ƒé¢˜

#### é¢˜å‹1ï¼šå†™æ­£åˆ™è¡¨è¾¾å¼

**é¢˜ç›®ï¼š**å†™ä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼åŒ¹é…HTMLçš„`<img>`æ ‡ç­¾ï¼Œæå–srcå±æ€§

```html
<img src="photo.jpg" width="100">
```

<details>
<summary>ç­”æ¡ˆ</summary>

```python
# æ–¹æ¡ˆ1ï¼šåŒ¹é…æ•´ä¸ªæ ‡ç­¾ï¼Œæå–src
pattern = r'<img\s+[^>]*src="([^"]+)"[^>]*>'

# æ–¹æ¡ˆ2ï¼šåªæå–srcå€¼
pattern = r'src="([^"]+)"'

# æµ‹è¯•
html = '<img src="photo.jpg" width="100">'
m = re.search(pattern, html)
print(m.group(1))  # 'photo.jpg'
```

**è§£é‡Šï¼š**
```
<img\s+      â† <img åé¢è‡³å°‘1ä¸ªç©ºæ ¼
[^>]*        â† 0ä¸ªæˆ–å¤šä¸ªé>å­—ç¬¦ï¼ˆsrcå‰é¢å¯èƒ½æœ‰å…¶ä»–å±æ€§ï¼‰
src="([^"]+)" â† src="..." ï¼ˆæ•è·å¼•å·å†…çš„å†…å®¹ï¼‰
[^>]*        â† srcåé¢å¯èƒ½è¿˜æœ‰å…¶ä»–å±æ€§
>            â† å³å°–æ‹¬å·
```
</details>

---

#### é¢˜å‹2ï¼šè´ªå©ªåŒ¹é…é—®é¢˜

**é¢˜ç›®ï¼š**ä¸ºä»€ä¹ˆä¸‹é¢çš„æ­£åˆ™è¡¨è¾¾å¼ä¸èƒ½æ­£ç¡®åŒ¹é…æ¯ä¸ªå•ç‹¬çš„æ ‡ç­¾ï¼Ÿ

```python
text = "<p><b>text</b></p>"
pattern = '<.*>'
# ç»“æœï¼šåŒ¹é…æ•´ä¸ªå­—ç¬¦ä¸²
```

å¦‚ä½•ä¿®å¤ï¼Ÿ

<details>
<summary>ç­”æ¡ˆ</summary>

**é—®é¢˜åŸå› ï¼š**
```
.* æ˜¯è´ªå©ªåŒ¹é…ï¼Œä¼šå°½å¯èƒ½å¤šåœ°åŒ¹é…
ä»ç¬¬ä¸€ä¸ª < å¼€å§‹ï¼Œä¸€ç›´åŒ¹é…åˆ°æœ€åä¸€ä¸ª >
```

**ä¿®å¤æ–¹æ¡ˆ1ï¼šéè´ªå©ªåŒ¹é…**
```python
pattern = '<.*?>'
# ç»“æœï¼š<p>, <b>, </b>, </p>
```

**ä¿®å¤æ–¹æ¡ˆ2ï¼šå­—ç¬¦ç±»å–å**
```python
pattern = '<[^>]+>'
# [^>]+ åªåŒ¹é…"é>"å­—ç¬¦ï¼Œé‡åˆ°>å°±åœæ­¢
```
</details>

---

#### é¢˜å‹3ï¼šåå‘å¼•ç”¨

**é¢˜ç›®ï¼š**ç”¨åå‘å¼•ç”¨å†™ä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼ï¼ŒåŒ¹é…é‡å¤çš„å•è¯

```
è¾“å…¥ï¼š"the the cat"
åº”è¯¥åŒ¹é…ï¼š"the the"
```

<details>
<summary>ç­”æ¡ˆ</summary>

```python
pattern = r'\b(\w+)\s+\1\b'

# è§£é‡Šï¼š
\b     â† å•è¯è¾¹ç•Œï¼ˆç¡®ä¿æ˜¯å®Œæ•´å•è¯ï¼‰
(\w+)  â† ç¬¬1ç»„ï¼šç¬¬ä¸€ä¸ªå•è¯
\s+    â† è‡³å°‘1ä¸ªç©ºæ ¼
\1     â† åå‘å¼•ç”¨ï¼šå¿…é¡»åŒ¹é…ç¬¬1ç»„çš„å†…å®¹
\b     â† å•è¯è¾¹ç•Œ

# æµ‹è¯•
text = "the the cat and and dog"
matches = re.findall(pattern, text)
print(matches)  # ['the', 'and']
```
</details>

---

#### é¢˜å‹4ï¼šè®¡ç®—TTR

**é¢˜ç›®ï¼š**

ç»™å®štweetsï¼š
```python
tweets = [
    "I love Python",
    "I LOVE coding",
    "Python is great"
]
```

è®¡ç®—ï¼š
1. æ— é¢„å¤„ç†çš„TTRï¼ˆç”¨`.split()`åˆ†è¯ï¼‰
2. å°å†™åçš„TTR

<details>
<summary>ç­”æ¡ˆ</summary>

**1. æ— é¢„å¤„ç†ï¼š**
```python
tokens = []
for tweet in tweets:
    tokens.extend(tweet.split())

# tokens = ['I', 'love', 'Python', 'I', 'LOVE', 'coding', 'Python', 'is', 'great']
types = set(tokens)  # {'I', 'love', 'Python', 'LOVE', 'coding', 'is', 'great'}

num_types = 7
num_tokens = 9
TTR = 7/9 = 0.778
```

**2. å°å†™åï¼š**
```python
tokens = []
for tweet in tweets:
    tokens.extend(tweet.lower().split())

# tokens = ['i', 'love', 'python', 'i', 'love', 'coding', 'python', 'is', 'great']
types = set(tokens)  # {'i', 'love', 'python', 'coding', 'is', 'great'}

num_types = 6  # 'LOVE'å’Œ'love'åˆå¹¶äº†
num_tokens = 9
TTR = 6/9 = 0.667
```

**ç»“è®ºï¼š**å°å†™è½¬æ¢ä½¿TTRä¸‹é™
</details>

---

#### é¢˜å‹5ï¼šTwitteré¢„å¤„ç†

**é¢˜ç›®ï¼š**å†™æ­£åˆ™è¡¨è¾¾å¼æŠŠæ‰€æœ‰@mentionsæ›¿æ¢æˆ`<MENTIONS>`

```python
text = "Hey @user1 and @user2, check this out!"
```

<details>
<summary>ç­”æ¡ˆ</summary>

```python
pattern = r"@[a-zA-Z0-9_]+"
result = re.sub(pattern, "<MENTIONS>", text)
print(result)
# "Hey <MENTIONS> and <MENTIONS>, check this out!"

# è§£é‡Šï¼š
@              â† @ ç¬¦å·
[a-zA-Z0-9_]+  â† 1ä¸ªæˆ–å¤šä¸ªå­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿
```

**æ›´ä¸¥æ ¼çš„ç‰ˆæœ¬ï¼ˆTwitterç”¨æˆ·åé™åˆ¶15å­—ç¬¦ï¼‰ï¼š**
```python
pattern = r"@[a-zA-Z0-9_]{1,15}"
```
</details>

---

## å…«ã€è®°å¿†å£è¯€

### è´ªå©ªä¸éè´ªå©ª
```
æ˜Ÿå·è´ªå©ªåƒåˆ°åº•ï¼Œ
é—®å·èŠ‚åˆ¶åˆšåˆšå¥½ï¼Œ
HTMLæ ‡ç­¾åˆ†ä¸æ¸…ï¼Œ
åŠ ä¸ªé—®å·è§£çƒ¦æ¼ã€‚
```

### åå‘å¼•ç”¨
```
æ‹¬å·æ•è·ç¬¬ä¸€ç»„ï¼Œ
åæ–œæ•°å­—å†å¼•ç”¨ï¼Œ
å¼€é—­æ ‡ç­¾è¦é…å¯¹ï¼Œ
\1å¸®ä½ æ¥æŠŠå…³ã€‚
```

### æ–‡æœ¬é¢„å¤„ç†
```
å¤§å†™å°å†™è¦ç»Ÿä¸€ï¼Œ
æ ‡ç‚¹ç¬¦å·éœ€åˆ†ç¦»ï¼Œ
Twitterå…ƒç´ æ ‡å‡†åŒ–ï¼Œ
TTRè¶Šä½è¶Šå¥½è®°ã€‚
```

---

## ä¹ã€å¸¸è§é”™è¯¯

### âŒ é”™è¯¯1ï¼šå¿˜è®°ç”¨éè´ªå©ªåŒ¹é…

```python
# é”™è¯¯
pattern = '<.*>'  # åŒ¹é…æ•´ä¸ªå­—ç¬¦ä¸²
text = "<p><b>text</b></p>"
# ç»“æœï¼š<p><b>text</b></p>  â† ä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„ï¼

# æ­£ç¡®
pattern = '<.*?>'  # éè´ªå©ª
# ç»“æœï¼š<p>, <b>, </b>, </p>  â† æ¯ä¸ªæ ‡ç­¾å•ç‹¬åŒ¹é…
```

---

### âŒ é”™è¯¯2ï¼šåå‘å¼•ç”¨ä¸ç”¨raw string

```python
# é”™è¯¯
pattern = '<(\w+)>(.*?)</\1>'
# Pythonä¼šå°è¯•è§£é‡Š \1 ä½œä¸ºè½¬ä¹‰å­—ç¬¦ï¼ˆæŠ¥é”™ï¼‰

# æ­£ç¡®
pattern = r'<(\w+)>(.*?)</\1>'
# r'...' ä¿ç•™ \1 ä½œä¸ºæ­£åˆ™è¡¨è¾¾å¼çš„åå‘å¼•ç”¨
```

---

### âŒ é”™è¯¯3ï¼šæ•è·ç»„å’Œéæ•è·ç»„æ··æ·†

```python
text = "don't"
pattern = r"\w+(?:'\w+)?"

# æ‰§è¡Œ
m = re.search(pattern, text)
print(m.group(0))  # "don't"  â† æ•´ä¸ªåŒ¹é…
print(m.group(1))  # é”™è¯¯ï¼æ²¡æœ‰group(1)

# (?:...) æ˜¯éæ•è·ç»„ï¼Œä¸ä¼šè¢«ç¼–å·
```

---

### âŒ é”™è¯¯4ï¼šTTRè®¡ç®—å¿˜è®°æ’é™¤æ ‡ç‚¹

```python
# é”™è¯¯
tokens = ['I', 'love', 'Python', '.', '!']
types = set(tokens)  # 5ä¸ªï¼ˆåŒ…æ‹¬æ ‡ç‚¹ï¼‰
TTR = 5/5 = 1.0  â† ä¸å‡†ç¡®ï¼

# æ­£ç¡®
tokens = [t for t in tokens if re.search("[a-zA-Z0-9]+", t)]
# ['I', 'love', 'Python']
types = set(tokens)  # 3ä¸ª
TTR = 3/3 = 1.0  â† å‡†ç¡®ï¼
```

---

## åã€æ‰©å±•çŸ¥è¯†

### 1. Unicodeå±æ€§ï¼ˆé«˜çº§ï¼‰

```python
# åŒ¹é…æ‰€æœ‰æ±‰å­—
pattern = r'[\u4e00-\u9fff]+'

# åŒ¹é…æ‰€æœ‰emoji
pattern = r'[\U0001F600-\U0001F64F]+'
```

---

### 2. Verboseæ¨¡å¼ï¼ˆè®©æ­£åˆ™è¡¨è¾¾å¼æ›´æ˜“è¯»ï¼‰

```python
# ä¸ç”¨verboseï¼ˆéš¾è¯»ï¼‰
pattern = r'(?:[A-Z]\.)+|\w+(?:-\w+)*|\$?\d+(?:\.\d+)?%?|\.\.\.|\[.,;"\'?():_`-]'

# ç”¨verboseï¼ˆæ˜“è¯»ï¼‰
pattern = r'''(?x)
    (?:[A-Z]\.)+        # ç¼©å†™ï¼Œå¦‚ U.S.A.
  | \w+(?:-\w+)*        # å¸¦è¿å­—ç¬¦çš„è¯
  | \$?\d+(?:\.\d+)?%?  # è´§å¸å’Œç™¾åˆ†æ¯”
  | \.\.\.              # çœç•¥å·
  | [].,;"'?():_`-]     # æ ‡ç‚¹
'''
```

---

### 3. å®é™…åº”ç”¨åœºæ™¯

**åœºæ™¯1ï¼šæå–æ‰€æœ‰é‚®ç®±**
```python
pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
```

**åœºæ™¯2ï¼šéªŒè¯ç”µè¯å·ç **
```python
pattern = r'^\+?1?\d{9,15}$'
```

**åœºæ™¯3ï¼šæ¸…ç†HTML**
```python
clean_text = re.sub(r'<[^>]+>', '', html_text)
```

---

**ç¥ä½ è€ƒè¯•é¡ºåˆ©ï¼** ğŸ‰

**Lecture 5æ ¸å¿ƒè¦ç‚¹ï¼š**
- è´ªå©ªvséè´ªå©ªï¼š`.*` vs `.*?`
- å­—ç¬¦ç±»å–åï¼š`[^>]+`
- åå‘å¼•ç”¨ï¼š`\1`, `\2`ï¼ˆå¿…é¡»ç”¨`r'...'`ï¼‰
- å‰ç»æ–­è¨€ï¼š`(?=...)`
- éæ•è·ç»„ï¼š`(?:...)`
- TTR = Types / Tokens
- é¢„å¤„ç†é™ä½TTRï¼Œæœ‰åˆ©äºæœºå™¨å­¦ä¹ 

**è®°ä½ï¼š**ç†è§£æ¯ä¸ªç¬¦å·çš„å«ä¹‰ï¼Œèƒ½æ‰‹å·¥æ¨¡æ‹ŸåŒ¹é…è¿‡ç¨‹ï¼
